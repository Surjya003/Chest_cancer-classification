{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\surjy\\\\OneDrive\\\\Desktop\\\\chest_cancer.py'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_augmentation: bool\n",
    "    params_image_size: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnclassifier.constants import *\n",
    "from cnnclassifier.utils.common import read_yaml, create_directories\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "        \n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"Data\")\n",
    "        create_directories([\n",
    "            Path(training.root_dir)\n",
    "        ])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE\n",
    "        )\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Self\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path\n",
    "        )\n",
    "\n",
    "        # Recompile the model to fix any optimizer mismatch issues\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "    def train_valid_generator(self):\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale=1./255,\n",
    "            validation_split=0.20\n",
    "        )\n",
    "\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1],\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"validation\",\n",
    "            shuffle=False,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "        if self.config.params_is_augmentation:\n",
    "            train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                horizontal_flip=True,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                **datagenerator_kwargs\n",
    "            )\n",
    "        else:\n",
    "            train_datagenerator = valid_datagenerator\n",
    "\n",
    "        self.train_generator = train_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"training\",\n",
    "            shuffle=True,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "\n",
    "    def train(self):\n",
    "        self.steps_per_epoch = self.train_generator.samples // self.train_generator.batch_size\n",
    "        self.validation_steps = self.valid_generator.samples // self.valid_generator.batch_size\n",
    "\n",
    "        self.model.fit(\n",
    "            self.train_generator,\n",
    "            epochs=self.config.params_epochs,\n",
    "            steps_per_epoch=self.steps_per_epoch,\n",
    "            validation_steps=self.validation_steps,\n",
    "            validation_data=self.valid_generator\n",
    "        )\n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-25 22:27:31,486: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-08-25 22:27:31,500: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-08-25 22:27:31,502: INFO: common: created directory at: artifacts]\n",
      "[2024-08-25 22:27:31,502: INFO: common: created directory at: artifacts\\training]\n",
      "[2024-08-25 22:27:31,820: WARNING: saving_utils: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.]\n",
      "Found 321 images belonging to 4 classes.\n",
      "Found 1292 images belonging to 4 classes.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\surjy\\OneDrive\\Desktop\\chest_cancer.py\\chestcancer\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 2s/step - accuracy: 0.4375 - loss: 1.7878 - val_accuracy: 0.5562 - val_loss: 0.9642\n",
      "Epoch 2/200\n",
      "\u001b[1m 1/80\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 1s/step - accuracy: 0.5833 - loss: 1.2582"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\surjy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5833 - loss: 1.2582 - val_accuracy: 0.0000e+00 - val_loss: 3.8710\n",
      "Epoch 3/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 2s/step - accuracy: 0.4840 - loss: 1.1853 - val_accuracy: 0.4375 - val_loss: 1.2157\n",
      "Epoch 4/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7500 - loss: 0.7913 - val_accuracy: 0.0000e+00 - val_loss: 5.0633\n",
      "Epoch 5/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 3s/step - accuracy: 0.5047 - loss: 1.3278 - val_accuracy: 0.5312 - val_loss: 1.0473\n",
      "Epoch 6/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5000 - loss: 0.7036 - val_accuracy: 0.0000e+00 - val_loss: 4.4735\n",
      "Epoch 7/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 3s/step - accuracy: 0.4622 - loss: 1.2768 - val_accuracy: 0.4000 - val_loss: 1.2873\n",
      "Epoch 8/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5000 - loss: 1.1340 - val_accuracy: 0.0000e+00 - val_loss: 4.2053\n",
      "Epoch 9/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 2s/step - accuracy: 0.5031 - loss: 1.3928 - val_accuracy: 0.4781 - val_loss: 1.4427\n",
      "Epoch 10/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4375 - loss: 1.2700 - val_accuracy: 0.0000e+00 - val_loss: 3.9064\n",
      "Epoch 11/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 2s/step - accuracy: 0.5141 - loss: 1.2268 - val_accuracy: 0.3938 - val_loss: 1.2848\n",
      "Epoch 12/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6875 - loss: 1.1900 - val_accuracy: 1.0000 - val_loss: 0.7573\n",
      "Epoch 13/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 2s/step - accuracy: 0.4722 - loss: 1.5618 - val_accuracy: 0.4437 - val_loss: 1.2719\n",
      "Epoch 14/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 1.0957 - val_accuracy: 0.0000e+00 - val_loss: 2.0600\n",
      "Epoch 15/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 2s/step - accuracy: 0.4805 - loss: 1.2503 - val_accuracy: 0.3906 - val_loss: 1.4088\n",
      "Epoch 16/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 1.0690 - val_accuracy: 0.0000e+00 - val_loss: 4.4801\n",
      "Epoch 17/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 2s/step - accuracy: 0.4980 - loss: 1.2989 - val_accuracy: 0.5719 - val_loss: 1.1609\n",
      "Epoch 18/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4375 - loss: 1.4438 - val_accuracy: 0.0000e+00 - val_loss: 7.3991\n",
      "Epoch 19/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 2s/step - accuracy: 0.4726 - loss: 1.2888 - val_accuracy: 0.5094 - val_loss: 0.9891\n",
      "Epoch 20/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5625 - loss: 1.2237 - val_accuracy: 0.0000e+00 - val_loss: 4.8580\n",
      "Epoch 21/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 3s/step - accuracy: 0.5058 - loss: 1.2315 - val_accuracy: 0.4844 - val_loss: 1.3369\n",
      "Epoch 22/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4375 - loss: 2.3904 - val_accuracy: 0.0000e+00 - val_loss: 9.8712\n",
      "Epoch 23/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 2s/step - accuracy: 0.5233 - loss: 1.2390 - val_accuracy: 0.5469 - val_loss: 2.7204\n",
      "Epoch 24/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5000 - loss: 2.8948 - val_accuracy: 0.0000e+00 - val_loss: 6.0805\n",
      "Epoch 25/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 2s/step - accuracy: 0.5212 - loss: 1.4533 - val_accuracy: 0.5562 - val_loss: 1.2609\n",
      "Epoch 26/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3125 - loss: 2.2668 - val_accuracy: 0.0000e+00 - val_loss: 3.6432\n",
      "Epoch 27/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 2s/step - accuracy: 0.4594 - loss: 1.4701 - val_accuracy: 0.5437 - val_loss: 1.0306\n",
      "Epoch 28/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5625 - loss: 1.1126 - val_accuracy: 0.0000e+00 - val_loss: 5.9701\n",
      "Epoch 29/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 4s/step - accuracy: 0.4927 - loss: 1.3013 - val_accuracy: 0.5063 - val_loss: 1.2742\n",
      "Epoch 30/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.2500 - loss: 2.4594 - val_accuracy: 0.0000e+00 - val_loss: 12.7724\n",
      "Epoch 31/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 4s/step - accuracy: 0.5186 - loss: 1.5769 - val_accuracy: 0.4938 - val_loss: 1.4123\n",
      "Epoch 32/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4375 - loss: 1.6759 - val_accuracy: 0.0000e+00 - val_loss: 5.3185\n",
      "Epoch 33/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 3s/step - accuracy: 0.5103 - loss: 1.3200 - val_accuracy: 0.3281 - val_loss: 1.7994\n",
      "Epoch 34/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3125 - loss: 1.0001 - val_accuracy: 0.0000e+00 - val_loss: 4.6391\n",
      "Epoch 35/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 3s/step - accuracy: 0.4876 - loss: 1.4714 - val_accuracy: 0.5219 - val_loss: 1.0620\n",
      "Epoch 36/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2500 - loss: 1.9487 - val_accuracy: 0.0000e+00 - val_loss: 6.8297\n",
      "Epoch 37/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 4s/step - accuracy: 0.4409 - loss: 1.3943 - val_accuracy: 0.5750 - val_loss: 2.2053\n",
      "Epoch 38/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5000 - loss: 2.4424 - val_accuracy: 0.0000e+00 - val_loss: 2.7714\n",
      "Epoch 39/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 3s/step - accuracy: 0.5107 - loss: 1.3370 - val_accuracy: 0.5625 - val_loss: 1.1186\n",
      "Epoch 40/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5625 - loss: 1.5182 - val_accuracy: 0.0000e+00 - val_loss: 9.3368\n",
      "Epoch 41/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 3s/step - accuracy: 0.5321 - loss: 1.2833 - val_accuracy: 0.5094 - val_loss: 1.0410\n",
      "Epoch 42/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5625 - loss: 0.9016 - val_accuracy: 0.0000e+00 - val_loss: 4.6845\n",
      "Epoch 43/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 3s/step - accuracy: 0.4892 - loss: 1.2514 - val_accuracy: 0.5688 - val_loss: 1.1781\n",
      "Epoch 44/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6250 - loss: 0.7816 - val_accuracy: 0.0000e+00 - val_loss: 4.6571\n",
      "Epoch 45/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 3s/step - accuracy: 0.5410 - loss: 1.1997 - val_accuracy: 0.5281 - val_loss: 1.2529\n",
      "Epoch 46/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5625 - loss: 1.0341 - val_accuracy: 0.0000e+00 - val_loss: 6.1750\n",
      "Epoch 47/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 3s/step - accuracy: 0.4708 - loss: 1.5782 - val_accuracy: 0.5688 - val_loss: 0.8682\n",
      "Epoch 48/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3750 - loss: 2.1813 - val_accuracy: 0.0000e+00 - val_loss: 3.6810\n",
      "Epoch 49/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 2s/step - accuracy: 0.4746 - loss: 1.4259 - val_accuracy: 0.4313 - val_loss: 1.8505\n",
      "Epoch 50/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5625 - loss: 1.4478 - val_accuracy: 0.0000e+00 - val_loss: 6.6854\n",
      "Epoch 51/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 3s/step - accuracy: 0.4960 - loss: 1.2014 - val_accuracy: 0.5000 - val_loss: 1.0025\n",
      "Epoch 52/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3750 - loss: 1.4665 - val_accuracy: 0.0000e+00 - val_loss: 2.6547\n",
      "Epoch 53/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 2s/step - accuracy: 0.5166 - loss: 1.1378 - val_accuracy: 0.5500 - val_loss: 2.0690\n",
      "Epoch 54/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4375 - loss: 3.0403 - val_accuracy: 0.0000e+00 - val_loss: 7.1073\n",
      "Epoch 55/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.5142 - loss: 1.5826 - val_accuracy: 0.4406 - val_loss: 1.2942\n",
      "Epoch 56/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4375 - loss: 1.0665 - val_accuracy: 0.0000e+00 - val_loss: 3.8316\n",
      "Epoch 57/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 2s/step - accuracy: 0.5404 - loss: 1.1580 - val_accuracy: 0.4469 - val_loss: 1.4489\n",
      "Epoch 58/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5833 - loss: 0.9502 - val_accuracy: 0.0000e+00 - val_loss: 5.8375\n",
      "Epoch 59/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.4905 - loss: 1.2266 - val_accuracy: 0.3438 - val_loss: 1.8977\n",
      "Epoch 60/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4375 - loss: 1.0034 - val_accuracy: 0.0000e+00 - val_loss: 7.5200\n",
      "Epoch 61/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.5117 - loss: 1.2580 - val_accuracy: 0.5469 - val_loss: 1.3751\n",
      "Epoch 62/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7500 - loss: 0.6885 - val_accuracy: 0.0000e+00 - val_loss: 5.6816\n",
      "Epoch 63/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5511 - loss: 1.2168 - val_accuracy: 0.4406 - val_loss: 1.2174\n",
      "Epoch 64/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5625 - loss: 1.1349 - val_accuracy: 0.0000e+00 - val_loss: 4.2254\n",
      "Epoch 65/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.5005 - loss: 1.1919 - val_accuracy: 0.4719 - val_loss: 1.2203\n",
      "Epoch 66/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 0.9786 - val_accuracy: 0.0000e+00 - val_loss: 6.2680\n",
      "Epoch 67/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.5239 - loss: 1.3110 - val_accuracy: 0.5469 - val_loss: 1.2989\n",
      "Epoch 68/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2500 - loss: 2.6132 - val_accuracy: 0.0000e+00 - val_loss: 9.9569\n",
      "Epoch 69/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.4894 - loss: 1.5330 - val_accuracy: 0.4062 - val_loss: 1.8912\n",
      "Epoch 70/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5625 - loss: 1.1496 - val_accuracy: 0.0000e+00 - val_loss: 4.9415\n",
      "Epoch 71/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.4909 - loss: 1.4730 - val_accuracy: 0.3156 - val_loss: 2.3562\n",
      "Epoch 72/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4375 - loss: 1.4922 - val_accuracy: 0.0000e+00 - val_loss: 3.3744\n",
      "Epoch 73/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.5137 - loss: 1.2657 - val_accuracy: 0.3469 - val_loss: 2.2372\n",
      "Epoch 74/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5625 - loss: 1.1452 - val_accuracy: 0.0000e+00 - val_loss: 8.2841\n",
      "Epoch 75/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.5162 - loss: 1.3919 - val_accuracy: 0.3000 - val_loss: 2.2986\n",
      "Epoch 76/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5000 - loss: 0.9808 - val_accuracy: 0.0000e+00 - val_loss: 3.8849\n",
      "Epoch 77/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.4972 - loss: 1.3708 - val_accuracy: 0.5437 - val_loss: 1.0471\n",
      "Epoch 78/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5625 - loss: 1.1144 - val_accuracy: 0.0000e+00 - val_loss: 10.1623\n",
      "Epoch 79/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5106 - loss: 1.2641 - val_accuracy: 0.2969 - val_loss: 2.3319\n",
      "Epoch 80/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5833 - loss: 0.9522 - val_accuracy: 0.0000e+00 - val_loss: 4.5855\n",
      "Epoch 81/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.4969 - loss: 1.4722 - val_accuracy: 0.5125 - val_loss: 1.3418\n",
      "Epoch 82/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 0.8451 - val_accuracy: 0.0000e+00 - val_loss: 10.2875\n",
      "Epoch 83/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.4955 - loss: 1.2960 - val_accuracy: 0.5125 - val_loss: 1.1140\n",
      "Epoch 84/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 0.5322 - val_accuracy: 0.0000e+00 - val_loss: 7.7658\n",
      "Epoch 85/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.5025 - loss: 1.2758 - val_accuracy: 0.3562 - val_loss: 2.1271\n",
      "Epoch 86/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4375 - loss: 1.3150 - val_accuracy: 0.0000e+00 - val_loss: 8.4947\n",
      "Epoch 87/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.5147 - loss: 1.2560 - val_accuracy: 0.5281 - val_loss: 1.2684\n",
      "Epoch 88/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5000 - loss: 1.2331 - val_accuracy: 0.0000e+00 - val_loss: 9.4878\n",
      "Epoch 89/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.5376 - loss: 1.2819 - val_accuracy: 0.5500 - val_loss: 1.3434\n",
      "Epoch 90/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4375 - loss: 1.5817 - val_accuracy: 0.0000e+00 - val_loss: 7.4716\n",
      "Epoch 91/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 2s/step - accuracy: 0.5336 - loss: 1.1450 - val_accuracy: 0.3906 - val_loss: 2.0150\n",
      "Epoch 92/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2500 - loss: 1.9443 - val_accuracy: 0.0000e+00 - val_loss: 4.7626\n",
      "Epoch 93/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.5265 - loss: 1.3290 - val_accuracy: 0.3844 - val_loss: 1.5906\n",
      "Epoch 94/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5000 - loss: 1.0507 - val_accuracy: 0.0000e+00 - val_loss: 6.0133\n",
      "Epoch 95/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.5221 - loss: 1.2591 - val_accuracy: 0.4313 - val_loss: 1.5524\n",
      "Epoch 96/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5000 - loss: 1.7717 - val_accuracy: 0.0000e+00 - val_loss: 4.8650\n",
      "Epoch 97/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 2s/step - accuracy: 0.4645 - loss: 1.2557 - val_accuracy: 0.4656 - val_loss: 1.5401\n",
      "Epoch 98/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2500 - loss: 2.3610 - val_accuracy: 0.0000e+00 - val_loss: 3.2137\n",
      "Epoch 99/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 2s/step - accuracy: 0.4877 - loss: 1.3657 - val_accuracy: 0.2906 - val_loss: 3.0555\n",
      "Epoch 100/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3750 - loss: 1.9550 - val_accuracy: 0.0000e+00 - val_loss: 10.3814\n",
      "Epoch 101/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5283 - loss: 1.3166 - val_accuracy: 0.4750 - val_loss: 1.6552\n",
      "Epoch 102/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4375 - loss: 0.9549 - val_accuracy: 0.0000e+00 - val_loss: 12.9873\n",
      "Epoch 103/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5224 - loss: 1.2381 - val_accuracy: 0.5469 - val_loss: 1.1123\n",
      "Epoch 104/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 1.0352 - val_accuracy: 0.0000e+00 - val_loss: 5.7427\n",
      "Epoch 105/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.5349 - loss: 1.3795 - val_accuracy: 0.4187 - val_loss: 1.4022\n",
      "Epoch 106/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3125 - loss: 2.0292 - val_accuracy: 0.0000e+00 - val_loss: 2.3444\n",
      "Epoch 107/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5004 - loss: 1.2612 - val_accuracy: 0.4375 - val_loss: 2.0201\n",
      "Epoch 108/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3125 - loss: 1.9016 - val_accuracy: 0.0000e+00 - val_loss: 7.8591\n",
      "Epoch 109/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.4718 - loss: 1.4224 - val_accuracy: 0.4656 - val_loss: 1.4297\n",
      "Epoch 110/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5625 - loss: 1.3709 - val_accuracy: 0.0000e+00 - val_loss: 6.4638\n",
      "Epoch 111/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.5014 - loss: 1.2813 - val_accuracy: 0.4344 - val_loss: 2.1395\n",
      "Epoch 112/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2500 - loss: 2.1820 - val_accuracy: 0.0000e+00 - val_loss: 4.1221\n",
      "Epoch 113/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5169 - loss: 1.3126 - val_accuracy: 0.3719 - val_loss: 2.5035\n",
      "Epoch 114/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 1.1827 - val_accuracy: 0.0000e+00 - val_loss: 9.7621\n",
      "Epoch 115/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5203 - loss: 1.2190 - val_accuracy: 0.4812 - val_loss: 1.1856\n",
      "Epoch 116/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5625 - loss: 1.2445 - val_accuracy: 0.0000e+00 - val_loss: 4.5707\n",
      "Epoch 117/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5232 - loss: 1.2475 - val_accuracy: 0.4969 - val_loss: 1.5361\n",
      "Epoch 118/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3750 - loss: 1.3886 - val_accuracy: 0.0000e+00 - val_loss: 8.6018\n",
      "Epoch 119/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.5420 - loss: 1.1999 - val_accuracy: 0.4094 - val_loss: 1.4431\n",
      "Epoch 120/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5625 - loss: 1.1841 - val_accuracy: 0.0000e+00 - val_loss: 4.0438\n",
      "Epoch 121/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.4862 - loss: 1.2301 - val_accuracy: 0.2656 - val_loss: 2.9139\n",
      "Epoch 122/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3125 - loss: 1.7263 - val_accuracy: 0.0000e+00 - val_loss: 4.8445\n",
      "Epoch 123/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5558 - loss: 1.0721 - val_accuracy: 0.3875 - val_loss: 1.5682\n",
      "Epoch 124/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 0.9490 - val_accuracy: 0.0000e+00 - val_loss: 5.2901\n",
      "Epoch 125/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5105 - loss: 1.1785 - val_accuracy: 0.3562 - val_loss: 2.2178\n",
      "Epoch 126/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5000 - loss: 1.4238 - val_accuracy: 0.0000e+00 - val_loss: 10.9134\n",
      "Epoch 127/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.4912 - loss: 1.3023 - val_accuracy: 0.2594 - val_loss: 2.9750\n",
      "Epoch 128/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3750 - loss: 1.3470 - val_accuracy: 0.0000e+00 - val_loss: 8.2929\n",
      "Epoch 129/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.4684 - loss: 1.4008 - val_accuracy: 0.3969 - val_loss: 1.8092\n",
      "Epoch 130/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4375 - loss: 1.4623 - val_accuracy: 0.0000e+00 - val_loss: 7.6399\n",
      "Epoch 131/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.4970 - loss: 1.3120 - val_accuracy: 0.5188 - val_loss: 1.2709\n",
      "Epoch 132/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5000 - loss: 1.2430 - val_accuracy: 0.0000e+00 - val_loss: 6.5812\n",
      "Epoch 133/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.5109 - loss: 1.3179 - val_accuracy: 0.5656 - val_loss: 1.2055\n",
      "Epoch 134/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5000 - loss: 1.4300 - val_accuracy: 0.0000e+00 - val_loss: 9.1682\n",
      "Epoch 135/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.5082 - loss: 1.2981 - val_accuracy: 0.5031 - val_loss: 1.1420\n",
      "Epoch 136/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5000 - loss: 0.9870 - val_accuracy: 0.0000e+00 - val_loss: 5.0787\n",
      "Epoch 137/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.5071 - loss: 1.2630 - val_accuracy: 0.2375 - val_loss: 3.8717\n",
      "Epoch 138/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2500 - loss: 1.9599 - val_accuracy: 0.0000e+00 - val_loss: 13.4258\n",
      "Epoch 139/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5260 - loss: 1.3308 - val_accuracy: 0.2688 - val_loss: 2.7043\n",
      "Epoch 140/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5625 - loss: 1.0009 - val_accuracy: 0.0000e+00 - val_loss: 5.2573\n",
      "Epoch 141/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5277 - loss: 1.2162 - val_accuracy: 0.3281 - val_loss: 2.2650\n",
      "Epoch 142/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5000 - loss: 2.3488 - val_accuracy: 0.0000e+00 - val_loss: 10.2227\n",
      "Epoch 143/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5158 - loss: 1.3286 - val_accuracy: 0.5156 - val_loss: 1.3636\n",
      "Epoch 144/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4375 - loss: 1.4686 - val_accuracy: 0.0000e+00 - val_loss: 9.7430\n",
      "Epoch 145/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5050 - loss: 1.2455 - val_accuracy: 0.2656 - val_loss: 2.7395\n",
      "Epoch 146/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 0.9492 - val_accuracy: 0.0000e+00 - val_loss: 9.4292\n",
      "Epoch 147/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.4976 - loss: 1.2067 - val_accuracy: 0.5531 - val_loss: 0.9308\n",
      "Epoch 148/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5625 - loss: 1.7898 - val_accuracy: 0.0000e+00 - val_loss: 5.3704\n",
      "Epoch 149/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5263 - loss: 1.2535 - val_accuracy: 0.4031 - val_loss: 2.0474\n",
      "Epoch 150/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 2.0495 - val_accuracy: 0.0000e+00 - val_loss: 3.7644\n",
      "Epoch 151/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.5246 - loss: 1.2651 - val_accuracy: 0.5031 - val_loss: 1.0541\n",
      "Epoch 152/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3750 - loss: 1.2924 - val_accuracy: 0.0000e+00 - val_loss: 4.6156\n",
      "Epoch 153/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.4609 - loss: 1.2580 - val_accuracy: 0.5312 - val_loss: 0.9561\n",
      "Epoch 154/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3750 - loss: 1.8496 - val_accuracy: 0.0000e+00 - val_loss: 4.8796\n",
      "Epoch 155/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.4924 - loss: 1.3320 - val_accuracy: 0.4812 - val_loss: 1.2737\n",
      "Epoch 156/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4375 - loss: 1.4236 - val_accuracy: 0.0000e+00 - val_loss: 6.0720\n",
      "Epoch 157/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5442 - loss: 1.2246 - val_accuracy: 0.3688 - val_loss: 2.5739\n",
      "Epoch 158/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5000 - loss: 1.9017 - val_accuracy: 0.0000e+00 - val_loss: 5.2480\n",
      "Epoch 159/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5248 - loss: 1.2745 - val_accuracy: 0.5312 - val_loss: 1.0113\n",
      "Epoch 160/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 0.9206 - val_accuracy: 0.0000e+00 - val_loss: 2.3572\n",
      "Epoch 161/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5143 - loss: 1.2736 - val_accuracy: 0.2750 - val_loss: 2.5270\n",
      "Epoch 162/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3750 - loss: 1.3864 - val_accuracy: 0.0000e+00 - val_loss: 8.8721\n",
      "Epoch 163/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.4808 - loss: 1.3164 - val_accuracy: 0.5625 - val_loss: 0.9402\n",
      "Epoch 164/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4375 - loss: 1.7810 - val_accuracy: 0.0000e+00 - val_loss: 6.4691\n",
      "Epoch 165/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5421 - loss: 1.2063 - val_accuracy: 0.2875 - val_loss: 2.7202\n",
      "Epoch 166/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5625 - loss: 1.1323 - val_accuracy: 0.0000e+00 - val_loss: 6.2518\n",
      "Epoch 167/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5031 - loss: 1.5402 - val_accuracy: 0.5688 - val_loss: 1.2744\n",
      "Epoch 168/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3750 - loss: 1.4700 - val_accuracy: 0.0000e+00 - val_loss: 12.3143\n",
      "Epoch 169/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.5245 - loss: 1.1998 - val_accuracy: 0.5469 - val_loss: 1.2793\n",
      "Epoch 170/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3750 - loss: 1.9740 - val_accuracy: 0.0000e+00 - val_loss: 5.7555\n",
      "Epoch 171/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5003 - loss: 1.1955 - val_accuracy: 0.5469 - val_loss: 1.2222\n",
      "Epoch 172/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5625 - loss: 1.2300 - val_accuracy: 0.0000e+00 - val_loss: 7.1188\n",
      "Epoch 173/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.5533 - loss: 1.1126 - val_accuracy: 0.3219 - val_loss: 2.2174\n",
      "Epoch 174/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3750 - loss: 1.7679 - val_accuracy: 0.0000e+00 - val_loss: 4.9063\n",
      "Epoch 175/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5209 - loss: 1.3146 - val_accuracy: 0.4750 - val_loss: 1.5371\n",
      "Epoch 176/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 1.4790 - val_accuracy: 0.0000e+00 - val_loss: 3.7943\n",
      "Epoch 177/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5092 - loss: 1.3314 - val_accuracy: 0.2812 - val_loss: 3.0038\n",
      "Epoch 178/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5000 - loss: 1.3530 - val_accuracy: 0.0000e+00 - val_loss: 4.9099\n",
      "Epoch 179/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5507 - loss: 1.1742 - val_accuracy: 0.3562 - val_loss: 2.0435\n",
      "Epoch 180/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1875 - loss: 1.7634 - val_accuracy: 0.0000e+00 - val_loss: 6.9147\n",
      "Epoch 181/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.5159 - loss: 1.2085 - val_accuracy: 0.3000 - val_loss: 2.2341\n",
      "Epoch 182/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3125 - loss: 1.2995 - val_accuracy: 0.0000e+00 - val_loss: 6.4168\n",
      "Epoch 183/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.5286 - loss: 1.3325 - val_accuracy: 0.4500 - val_loss: 1.6516\n",
      "Epoch 184/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7500 - loss: 0.6095 - val_accuracy: 0.0000e+00 - val_loss: 7.0007\n",
      "Epoch 185/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5375 - loss: 1.1340 - val_accuracy: 0.5000 - val_loss: 1.3142\n",
      "Epoch 186/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3750 - loss: 1.1953 - val_accuracy: 0.0000e+00 - val_loss: 10.1639\n",
      "Epoch 187/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5017 - loss: 1.4156 - val_accuracy: 0.3750 - val_loss: 1.7326\n",
      "Epoch 188/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5000 - loss: 1.7118 - val_accuracy: 0.0000e+00 - val_loss: 6.0540\n",
      "Epoch 189/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5034 - loss: 1.3267 - val_accuracy: 0.5219 - val_loss: 1.0774\n",
      "Epoch 190/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4375 - loss: 1.9932 - val_accuracy: 0.0000e+00 - val_loss: 4.7719\n",
      "Epoch 191/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5296 - loss: 1.3680 - val_accuracy: 0.4500 - val_loss: 1.4588\n",
      "Epoch 192/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5000 - loss: 1.9102 - val_accuracy: 0.0000e+00 - val_loss: 6.3463\n",
      "Epoch 193/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5125 - loss: 1.2121 - val_accuracy: 0.4656 - val_loss: 1.3010\n",
      "Epoch 194/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5000 - loss: 1.2616 - val_accuracy: 0.0000e+00 - val_loss: 5.9127\n",
      "Epoch 195/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5273 - loss: 1.2418 - val_accuracy: 0.5281 - val_loss: 1.1574\n",
      "Epoch 196/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5000 - loss: 1.4699 - val_accuracy: 0.0000e+00 - val_loss: 8.9820\n",
      "Epoch 197/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5285 - loss: 1.1865 - val_accuracy: 0.4187 - val_loss: 1.6914\n",
      "Epoch 198/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4375 - loss: 0.9710 - val_accuracy: 0.0000e+00 - val_loss: 8.0597\n",
      "Epoch 199/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.5078 - loss: 1.3814 - val_accuracy: 0.3594 - val_loss: 2.0793\n",
      "Epoch 200/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 0.7272 - val_accuracy: 0.0000e+00 - val_loss: 6.1016\n",
      "[2024-08-26 03:33:45,180: WARNING: saving_api: You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. ]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train()\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chestcancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
